---
title: "TRIAL"
teaching: 10
exercises: 0
questions:
- "Why sequence RNA?"

objectives:
- "Understanding the primary aims of this workshop"
keypoints:
- XXX
---

#### Important links

-   Analyzing RNA-seq data with DESeq2
    <http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html>

-   RNA-seq workflow: gene-level exploratory analysis and differential
    expression
    <https://bioconductor.org/help/course-materials/2017/CSAMA/labs/2-tuesday/lab-03-rnaseq/rnaseqGene_CSAMA2017.html>

-   Pre-processing of RNA-Seq daatsets (Used by Tracy)
    <https://compbiocore.github.io/deseq-workshop-1/assets/deseq_workshop_1.html>

> ## Load the R-libraries
> ~~~
>     suppressMessages({
>       library("DESeq2")
>      library("edgeR")
>       library("limma")
>       library("RColorBrewer")
>       library("gplots")
>       library("ggplot2")
>       library("EnhancedVolcano")
>       library("factoextra")
>       library("devtools")
>       library("rstudioapi")
>       library("dplyr")
>       library("tibble")
>       library("tidyverse")
>       library("pheatmap")
>       library("biomaRt")
>       library("annotables")
>       library("org.Mm.eg.db")
>       library("biobroom")
>       library("clusterProfiler")
>       #library("pathfindR")
>     })
> ~~~
> {: .language-bash}
{: .solution}

> ## Set the current path as the current working directory
> ~~~
> current_path <- getActiveDocumentContext()$path 
> setwd(dirname(current_path ))
> ~~~
> {: .language-bash}
{: .solution}

### Importing the Gene-count matrix (Generated by nfcore-rnaseq)

-   As input, the DESeq2 package expects count data as obtained, e.g.,
    from RNA-seq or another high-throughput sequencing experiment, in
    the form of a matrix of integer values.
-   The value in the i-th row and the j-th column of the matrix tells
    how many reads can be assigned to gene i in sample j.
-   The values in the matrix should be un-normalized counts or estimated
    counts of sequencing reads (for single-end RNA-seq) or fragments
    (for paired-end RNA-seq).
-   The DESeq2 model internally corrects for library size, so
    transformed or normalized values such as counts scaled by library
    size should not be used as input.

### Read Input data (Gene-count matrix generated by nfcore-rnaseq) —-

    counttable_original<-read.delim("GSE81082_count_matrix_ENSIDs_symbols_nr.txt", header=T, row.names=1) 

    # View the count matrix
    View(counttable_original)

    # Gene symbol as the identifier (when compared to ENSG ID)
    counttable<-counttable_original[,c("Symbol","WT1","WT2","WT3","KO1","KO2","KO3")]
    row.names(counttable) <- NULL
    # Convert Column  'GeneSymbol' to rowname)
    rownames(counttable) <- counttable$Symbol
    counttable<-counttable[,c("WT1","WT2","WT3","KO1","KO2","KO3")]
    #View(counttable)


    # There is that question of redundancy? Many genes same ENSG?- To be thought about and addressed

### Prepare DESeq2 object

-   We can perform deeper data exploration with DESeq2.

#### The DESeqDataSet

-   The object class used by the DESeq2 package to store the read counts
    and the intermediate estimated quantities during statistical
    analysis is the DESeqDataSet, which will usually be represented in
    the code here as an object dds.
-   Please see the
    [guide](http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)
    for package information.
-   We prepare the DESeq2 object with `design = ~1`. A design of ~1 is
    used for no experimental design and is useful for exploring QC of
    the data (not for DE).

<!-- -->

    # Define a condition variable 
    condition=c("Wild","Wild","Wild","KO","KO","KO")
    meta <- data.frame(row.names=colnames(counttable),condition)
    View(meta)


    dds <- DESeqDataSetFromMatrix(countData = counttable, 
                                  colData = meta, 
                                  design = ~1)

-   Blind dispersion estimation is not appropriate if one expects that
    many or the majority of genes (rows) will have large differences in
    counts which are explainable by the experimental design, and one
    wishes to transform the data for downstream analysis.
-   In this case, using blind dispersion estimation will lead to large
    estimates of dispersion, as it attributes differences due to
    experimental design as unwanted noise, and will result in overly
    shrinking the transformed values towards each other.
-   This
    [tutorial](https://compbiocore.github.io/deseq-workshop-1/assets/deseq_workshop_1.html)
    provides a nice deeper explanation of these concepts.

#### Log fold change + 1

    boxplot(log2((counttable)+1),las=3, col="red")

![](trial_files/figure-markdown_strict/unnamed-chunk-5-1.png)

### Data transformation

-   Count data is then transformed with `rlog` or `vst` before
    performing exploratory data analysis such as visualisation and
    clustering.
-   This transforms the raw count data (which is heteroskedatic -
    variance grows with the mean) into homoskedatic data (variance is
    not dependant on the mean). Both methods produce data on the log2
    scale, and normalize for other factors such as library size. Setting
    `blind=TRUE` (the default) should be used to compare samples in a
    manner wholly unbiased about the information about experimental
    groups, for example to perform sample QC.
-   This should not be performed during DE analysis, because a
    dispersion estimation that is blind to the experimental design may
    count treatment group differences as “noise” rather than real
    biological differences.

#### Variance stabilisting transformation (VST)

-   VST by default uses a subset of 1000 rows to estimate the dispersion
    trend. This method is much faster than rlog, and is recommended if
    you have hundreds of samples.

<!-- -->

    vst <- vst(dds, blind = TRUE)
    vst.data <- assay(vst)

#### Box plots

    boxplot(vst.data,las=3, col="red")

![](trial_files/figure-markdown_strict/unnamed-chunk-7-1.png)

-   Regularized log (rlog) takes a long time with 50 or more samples

<!-- -->

    # rld <- rlog(dds, blind=FALSE)

#### Heatmap of the sample-to-sample distances

-   A heatmap of this distance matrix gives us an overview over
    similarities and dissimilarities between samples.
-   We have to provide a hierarchical clustering hc to the heatmap
    function based on the sample distances, or else the heatmap function
    would calculate a clustering based on the distances between the
    rows/columns of the distance matrix.

<!-- -->

    sampleDists <- dist(t(assay(vst)))
    sampleDistMatrix <- as.matrix(sampleDists)
    rownames(sampleDistMatrix) <- paste(vst$condition, vst$type, sep="-")
    colnames(sampleDistMatrix) <- NULL
    colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
    pheatmap(sampleDistMatrix,
             clustering_distance_rows=sampleDists,
             clustering_distance_cols=sampleDists,
             col=colors)

![](trial_files/figure-markdown_strict/unnamed-chunk-9-1.png)

### Differential expression using the DESeqDataSet object

-   A DESeqDataSet object must have an associated design formula. The
    design formula expresses the variables which will be used in
    modeling.
-   The formula should be a tilde (~) followed by the variables with
    plus signs between them.
-   The design can be changed later, however then all differential
    analysis steps should be repeated, as the design formula is used to
    estimate the dispersions and to estimate the log2 fold changes of
    the model.
-   There are multiple ways of constructing a DESeqDataSet, depending on
    what pipeline was used upstream of DESeq2 to generated counts or
    estimated counts
-   Here we have a matrix (as read in a dataframe above) of read counts
    prepared from our previous analysis using nfcore-rnaseq pipeline.
-   So we use the function - DESeqDataSetFromMatrix

<!-- -->

    dds <- DESeqDataSetFromMatrix(countData = counttable,
                                  colData = meta,
                                  design = ~ condition)

    ## Warning in DESeqDataSet(se, design = design, ignoreRank): some variables in
    ## design formula are characters, converting to factors

    # Check and discuss if required what is the warning!
    #Warning in DESeqDataSet(se, design = design, ignoreRank) :
    #  some variables in design formula are characters, converting to factors

### Pre-filtering

-   While it is not necessary to pre-filter low count genes before
    running the DESeq2 functions, there are two reasons which make
    pre-filtering useful:
-   By removing rows in which there are very few reads, we reduce the
    memory size of the dds data object, and
-   We increase the speed of the transformation and testing functions
    within DESeq2.
-   Filter to remove lowly expressed genes - keeping those with more
    than 1 counts per million in at least 4 / 6 samples

<!-- -->

    keep <- rowSums(cpm(counttable)>1) >=4
    dds <- dds[keep,]

### Explicitly set the factors levels

-   By default, R will choose a reference level for factors based on
    alphabetical order.
-   So if you never tell the DESeq2 functions which level you want to
    compare against (e.g. which level represents the control group), the
    comparisons will be based on the alphabetical order of the levels.
-   Setting the factor levels can be done in two ways

<!-- -->

    # Using factor
    #dds$condition <- factor(dds$condition, levels = c("Wild","KO"))

    #OR

    # using relevel, just specifying the reference level:
    dds$condition ~ relevel(dds$condition, ref="Wild")

    ## dds$condition ~ relevel(dds$condition, ref = "Wild")

## Exploratory analysis and visualization

### Data transformations

-   Count data transformations

-   In order to test for differential expression, we operate on raw
    counts and use discrete distributions as described in the previous
    section on differential expression. However for other downstream
    analyses – e.g. for visualization or clustering – it might be useful
    to work with transformed versions of the count data.

-   Maybe the most obvious choice of transformation is the logarithm.

-   1.  Variance stabilizing transformation (vst)

-   1.  Regularized log transformation (rlog)

### Principal component plot of the samples

-   Related to the distance matrix is the PCA plot, which shows the
    samples in the 2D plane spanned by their first two principal
    components.
-   This type of plot is useful for visualizing the overall effect of
    experimental covariates and batch effects.

<!-- -->

    vsd <- vst(dds, blind=FALSE)
    z<-plotPCA(vsd, intgroup=c("condition"))
    z+ geom_text(aes_string(x = "PC1", y = "PC2", label = "name"),color = "black",size = 4)

![](trial_files/figure-markdown_strict/unnamed-chunk-13-1.png)

    # for the subsetted data
    # There is an error with vsd (possibly due to very few rows/ genes with valid expression)
      # https://support.bioconductor.org/p/98634/
      # problem is that your expression matrix doesn't have more than 1000 genes (rows) in it.

    # Using rlog (regularized log) transformation is slower but it works in this case for very few genes 
    #rld <- rlog(dds)
    #z<-plotPCA(rld, intgroup=c("condition"))
    #z+ geom_text(aes_string(x = "PC1", y = "PC2", label = "name"), color = "black",size = 4)

### Scree plot

    pca=prcomp(t(assay(vsd)),scale=FALSE)
    options(repr.plot.width=0.5, repr.plot.height=0.5)
    fviz_eig(pca, addlabels = TRUE)

![](trial_files/figure-markdown_strict/unnamed-chunk-14-1.png)

    # pca
    #https://www.biostars.org/p/289196/

## Differential expression analysis

# The DESeq function

    dds <- DESeq(dds)

    ## estimating size factors

    ## estimating dispersions

    ## gene-wise dispersion estimates

    ## mean-dispersion relationship

    ## final dispersion estimates

    ## fitting model and testing

    res <- results(dds)
    res

    ## log2 fold change (MLE): condition Wild vs KO 
    ## Wald test p-value: condition Wild vs KO 
    ## DataFrame with 13412 rows and 6 columns
    ##         baseMean log2FoldChange     lfcSE       stat    pvalue      padj
    ##        <numeric>      <numeric> <numeric>  <numeric> <numeric> <numeric>
    ## Zranb2  1539.042      -0.443373  0.256068  -1.731465 0.0833689  0.216840
    ## Miat     306.694       0.461551  0.378942   1.217999 0.2232243  0.407582
    ## Bcap31  3214.035      -0.257193  0.176392  -1.458073 0.1448205  0.309788
    ## Ctbs     122.193       0.141851  0.209743   0.676305 0.4988469  0.674451
    ## Maob     268.754       0.161518  0.190735   0.846820 0.3970957  0.586695
    ## ...          ...            ...       ...        ...       ...       ...
    ## Haus7   415.3751     -0.4579171  0.216959 -2.1106142 0.0348055 0.1236545
    ## Bcorl1  521.2514      0.3039260  0.207519  1.4645695 0.1430384 0.3073553
    ## H6pd    666.8968      0.6597497  0.265548  2.4844878 0.0129738 0.0646865
    ## Myo15    21.8238      0.0233713  0.420661  0.0555587 0.9556934 0.9757630
    ## Klhl7   529.1959     -0.2133819  0.256608 -0.8315480 0.4056641 0.5941822

    # padj 0.05
    res_padj0.05<-results(dds,alpha=0.05)
    summary(res_padj0.05)

    ## 
    ## out of 13412 with nonzero total read count
    ## adjusted p-value < 0.05
    ## LFC > 0 (up)       : 1092, 8.1%
    ## LFC < 0 (down)     : 1216, 9.1%
    ## outliers [1]       : 4, 0.03%
    ## low counts [2]     : 0, 0%
    ## (mean count < 19)
    ## [1] see 'cooksCutoff' argument of ?results
    ## [2] see 'independentFiltering' argument of ?results

    resSig005_subset<-subset(res_padj0.05, padj < 0.05)
    write.table(resSig005_subset, "res_DeSeq2_FDR0.05_comparison_Wild_vs_KO_FUllMatrix.tab", sep="\t", col.names=NA, quote=F)

    # padj 0.1
    res_padj0.1<-results(dds,alpha=0.1)
    summary(res_padj0.1)

    ## 
    ## out of 13412 with nonzero total read count
    ## adjusted p-value < 0.1
    ## LFC > 0 (up)       : 1623, 12%
    ## LFC < 0 (down)     : 1709, 13%
    ## outliers [1]       : 4, 0.03%
    ## low counts [2]     : 0, 0%
    ## (mean count < 19)
    ## [1] see 'cooksCutoff' argument of ?results
    ## [2] see 'independentFiltering' argument of ?results

    resSig01_subset<-subset(res_padj0.1, padj < 0.1)
    write.table(resSig01_subset, "res_DeSeq2_FDR0.1_comparison_Wild_vs_KO_FUllMatrix.tab", sep="\t", col.names=NA, quote=F)

    # Writing normalized counts
    normalised_counts<-counts(dds,normalized=TRUE)
    write.table(normalised_counts, "normalised_all_samples_DeSeq2_FUllMatrix.tab", sep="\t", col.names=NA, quote=F)

### Plot dispersion estimates

    plotDispEsts(dds, ylim = c(1e-6,1e3) )

![](trial_files/figure-markdown_strict/unnamed-chunk-16-1.png)

### Plot histogram of p-values

    #hist(resSig005_subset$pvalue, col = "lavender", main = title, xlab = "p-values")

### Tidy and annotate results

-   Ordering by padj value
-   Get gene names for ensembl IDs.

<!-- -->

    # https://github.com/stephenturner/annotables
    # grch38 comes from library(annotables)
    res_tidy.DE = tidy.DESeqResults(resSig005_subset)

    ## Warning: `tbl_df()` was deprecated in dplyr 1.0.0.
    ## Please use `tibble::as_tibble()` instead.
    ## This warning is displayed once every 8 hours.
    ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.

    res_tidy.DE <- res_tidy.DE %>% arrange(p.adjusted) %>% inner_join(grcm38, by = c(gene = "symbol")) %>% dplyr::select(gene,baseMean, estimate, stderror, statistic, p.value, p.adjusted) 
    #res_tidy.DE

### Volcano plot

\#`{r} #EnhancedVolcano(res_tidy.DE, #    lab = res_tidy.DE$gene, #    x = 'estimate', #    y = 'p.value', #    title = title, #    pointSize = 2.0, #    labSize = 10.0) #`

### GO analysis

-   Prepare input.
-   Filter for significant up and down regulated genes by P adjust and
    log fold change.

<!-- -->

    # P adj < 0.05 
    sig <- res_tidy.DE[res_tidy.DE$p.adjusted < 0.05, ]

    # Upregulated: LFC > 1, remove NAs
    sig.up <- sig[sig$estimate > 1, ]
    sig.up <- na.omit(sig.up)
    sig.up.LFC <- sig.up$estimate
    names(sig.up.LFC) <- sig.up$gene
    # Sort by LFC, decreasing
    sig.up.LFC <- sort(sig.up.LFC, decreasing = TRUE)

    # Downregulated: LFC < 1, remove NAs
    sig.dn <- sig[sig$estimate < 1, ]
    sig.dn <- na.omit(sig.dn)
    sig.dn.LFC <- sig.dn$estimate
    names(sig.dn.LFC) <- sig.dn$gene
    # Sort by LFC, decreasing
    sig.dn.LFC <- sort(sig.dn.LFC, decreasing = TRUE)

### Dotplot

-   Upregulated in KO (Down-regulated in WT) - So we call this
    DOWNREGULATED

<!-- -->

    ego.up <- enrichGO(gene = names(sig.up.LFC),
                          OrgDb = org.Mm.eg.db, 
                          keyType = 'SYMBOL',
                          readable = FALSE,
                          ont = "ALL",
                          pAdjustMethod = "BH",
                          pvalueCutoff = 0.05, 
                          qvalueCutoff = 0.2)

    dotplot(ego.up, showCategory=20,font.size = 20)

![](trial_files/figure-markdown_strict/unnamed-chunk-21-1.png)

    cnetplot(ego.up, 
             categorySize="pvalue", 
             foldChange=sig.up.LFC,
             cex_label_gene = 1,
             showCategory = 5,cex_label_category=1.5,shadowtext='category')

![](trial_files/figure-markdown_strict/unnamed-chunk-22-1.png)

### Downregulated in KO

    ego.dn <- enrichGO(gene = names(sig.dn.LFC),
                          OrgDb = org.Mm.eg.db, 
                          keyType = 'SYMBOL',
                          readable = FALSE,
                          ont = "ALL",
                          pAdjustMethod = "BH",
                          pvalueCutoff = 0.05, 
                          qvalueCutoff = 0.2)

    dotplot(ego.dn, showCategory=20,font.size = 20)

![](trial_files/figure-markdown_strict/unnamed-chunk-24-1.png)

    cnetplot(ego.dn, 
             categorySize="pvalue", 
             foldChange=sig.dn.LFC,
             cex_label_gene = 0.7,
             showCategory = 5,cex_label_category=1.5,shadowtext='category')

    ## Warning: ggrepel: 12 unlabeled data points (too many overlaps). Consider
    ## increasing max.overlaps

![](trial_files/figure-markdown_strict/unnamed-chunk-25-1.png)
